// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`integration:tokenize > default constructs > should tokenize empty file 1`] = `
tokens[2]
較럭0 sof (1:1-1:1, 0-0)
較덕1 eof (1:1-1:1, 0-0)
`;

exports[`integration:tokenize > default constructs > should tokenize non-empty file 1`] = `
tokens[2]
較럭0 sof (1:1-1:1, 0-0)
較덕1 eof (22:1-22:1, 304-304)
`;

exports[`integration:tokenize > user constructs > non-empty file > sample 0 1`] = `
tokens[3]
較럭0 sof (1:1-1:1, 0-0)
較럭1 inlineTag (1:1-1:17, 0-16)
較덕2 eof (2:1-2:1, 17-17)
`;

exports[`integration:tokenize > user constructs > non-empty file > sample 1 1`] = `
tokens[13]
較럭0  sof (1:1-1:1, 0-0)
較럭1  punctuator "=" (1:10-1:11, 9-10)
較럭2  string "\\"hello 游녦\\"" (1:12-1:21, 11-20)
較럭3  punctuator ";" (1:21-1:22, 20-21)
較럭4  punctuator "." (2:8-2:9, 29-30)
較럭5  punctuator "(" (2:12-2:13, 33-34)
較럭6  punctuator "\\\\" (2:13-2:14, 34-35)
較럭7  punctuator "\\\\" (2:19-2:20, 40-41)
較럭8  punctuator ")" (2:25-2:26, 46-47)
較럭9  punctuator ";" (2:26-2:27, 47-48)
較럭10 punctuator "/" (2:28-2:29, 49-50)
較럭11 punctuator "/" (2:29-2:30, 50-51)
較덕12 eof (3:1-3:1, 60-60)
`;

exports[`integration:tokenize > user constructs > non-empty file > sample 2 1`] = `
tokens[8]
較럭0 sof (1:1-1:1, 0-0)
較럭1 string "'游땘'" (1:1-1:4, 0-3)
較럭2 string "\\"游녨\\"" (2:1-2:4, 4-7)
較럭3 punctuator "\\\\" (3:1-3:2, 8-9)
較럭4 punctuator "'" (3:2-3:3, 9-10)
較럭5 punctuator "\\\\" (3:4-3:5, 11-12)
較럭6 punctuator "'" (3:5-3:6, 12-13)
較덕7 eof (4:1-4:1, 14-14)
`;

exports[`integration:tokenize > user constructs > non-empty file > sample 3 1`] = `
tokens[42]
較럭0  sof (1:1-1:1, 0-0)
較럭1  number "0" (1:1-1:2, 0-1)
較럭2  whitespace "\\n" (1:2-2:1, 1-2)
較럭3  bigint "0n" (2:1-2:3, 2-4)
較럭4  whitespace "\\n" (2:3-3:1, 4-5)
較럭5  number "1" (3:1-3:2, 5-6)
較럭6  whitespace "\\n" (3:2-4:1, 6-7)
較럭7  bigint "1n" (4:1-4:3, 7-9)
較럭8  whitespace "\\n" (4:3-5:1, 9-10)
較럭9  number "2" (5:1-5:2, 10-11)
較럭10 whitespace "\\n" (5:2-6:1, 11-12)
較럭11 bigint "2n" (6:1-6:3, 12-14)
較럭12 whitespace "\\n" (6:3-7:1, 14-15)
較럭13 number "3" (7:1-7:2, 15-16)
較럭14 whitespace "\\n" (7:2-8:1, 16-17)
較럭15 bigint "3n" (8:1-8:3, 17-19)
較럭16 whitespace "\\n" (8:3-9:1, 19-20)
較럭17 number "4" (9:1-9:2, 20-21)
較럭18 whitespace "\\n" (9:2-10:1, 21-22)
較럭19 bigint "4n" (10:1-10:3, 22-24)
較럭20 whitespace "\\n" (10:3-11:1, 24-25)
較럭21 number "5" (11:1-11:2, 25-26)
較럭22 whitespace "\\n" (11:2-12:1, 26-27)
較럭23 bigint "5n" (12:1-12:3, 27-29)
較럭24 whitespace "\\n" (12:3-13:1, 29-30)
較럭25 number "6" (13:1-13:2, 30-31)
較럭26 whitespace "\\n" (13:2-14:1, 31-32)
較럭27 bigint "6n" (14:1-14:3, 32-34)
較럭28 whitespace "\\n" (14:3-15:1, 34-35)
較럭29 number "7" (15:1-15:2, 35-36)
較럭30 whitespace "\\n" (15:2-16:1, 36-37)
較럭31 bigint "7n" (16:1-16:3, 37-39)
較럭32 whitespace "\\n" (16:3-17:1, 39-40)
較럭33 number "8" (17:1-17:2, 40-41)
較럭34 whitespace "\\n" (17:2-18:1, 41-42)
較럭35 bigint "8n" (18:1-18:3, 42-44)
較럭36 whitespace "\\n" (18:3-19:1, 44-45)
較럭37 number "9" (19:1-19:2, 45-46)
較럭38 whitespace "\\n" (19:2-20:1, 46-47)
較럭39 bigint "9n" (20:1-20:3, 47-49)
較럭40 whitespace "\\n" (20:3-21:1, 49-50)
較덕41 eof (21:1-21:1, 50-50)
`;

exports[`integration:tokenize > user constructs > should tokenize empty file 1`] = `
tokens[2]
較럭0 sof (1:1-1:1, 0-0)
較덕1 eof (1:1-1:1, 0-0)
`;
